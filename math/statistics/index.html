<!DOCTYPE html>
<!-- Academia (pandoc HTML5 template)
     designer:     soimort
     last updated: 2016-05-07 -->
<html>
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <meta name="author" content="Mort Yao">
    <meta name="dcterms.date" content="2017-01-08">
    <title>Basic Statistics</title>
    <link rel="canonical" href="https://wiki.soimort.org/math/statistics">
    <style type="text/css">code { white-space: pre; }</style>
    <link rel="stylesheet" href="//cdn.soimort.org/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="//cdn.soimort.org/mathsvg/latest/mathsvg.min.css">
    <link rel="stylesheet" href="//cdn.soimort.org/fonts/latest/Latin-Modern-Roman.css">
    <link rel="stylesheet" href="//cdn.soimort.org/fonts/latest/Latin-Modern-Mono.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="/__/css/style.css">
    <link rel="stylesheet" href="/__/css/pygments.css">
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
    <![endif]-->
    <script src="//cdn.soimort.org/jk/20160504/jk.min.js"></script>
    <script src="//cdn.soimort.org/mathsvg/latest/mathsvg.min.js"></script>
    <script src="/__/js/jk-minibar.js"></script>
    <link rel="icon" href="/favicon.png">
    <link rel="apple-touch-icon" href="/favicon.png">
  </head>
  <body>
    <main><article>
      <header>
        <h1 class="title">Basic Statistics</h1>
        <address class="author">Mort Yao</address>
        <!-- h3 class="date">2017-01-08</h3 -->
      </header>
      <nav id="TOC">
<ul>
<li><a href="#descriptive-statistics"><span class="toc-section-number">1</span> Descriptive Statistics</a></li>
<li><a href="#inferential-statistics"><span class="toc-section-number">2</span> Inferential Statistics</a></li>
</ul>
      </nav>
      <div id="content">
<p>Basic probability theory and statistics:</p>
<ul>
<li>Michael Mitzenmacher and Eli Upfal. <strong><em>Probability and Computing: Randomized Algorithms and Probabilistic Analysis</em></strong>.</li>
<li>Michael Baron. <strong><em>Probability and Statistics for Computer Scientists, 2nd edition</em></strong>.</li>
</ul>
<hr />
<p>Statistics applies tools of the probability theory to the study of data (either a <em>sample</em> or the <em>population</em>):</p>
<ul>
<li><em>Descriptive statistics</em> quantitatively describe or summarize features of a sample.</li>
<li><em>Inferential statistics</em> use random sample data to infer properties about a larger population.</li>
</ul>
<section id="descriptive-statistics" class="level1">
<h1><span class="header-section-number">1</span> Descriptive Statistics</h1>
<p>To describe a sample (data set) quantitatively, three kinds of measures are commonly used: central tendency (often in connection with the first raw moment), dispersion / variability (often in connection with the second central moment) and shape (often in connection with higher-order central moments or cumulants).</p>
<section id="central-tendency" class="level2">
<h2><span class="header-section-number">1.1</span> Central Tendency</h2>
<p><strong>Arithmetic mean (AM, <span class="math inline">\(\mu\)</span>).</strong> Sum of values of a data set divided by number of values: <span class="math display">\[\mu = \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i\]</span> Example: Given data set <span class="math inline">\(\{1,2,2,3,4,7,9\}\)</span>, the arithmetic mean is <span class="math inline">\(\mu = \frac{1+2+2+3+4+7+9}{7} = 4\)</span>.</p>
<p><strong>Remark 1.1.1. (Difference between arithmetic mean and expectation)</strong> Note that although the formula of an arithmetic mean looks similar to the one of a mathematical expectation in probability theory, arithmetic mean is defined on a given sample (data set), while expectation is defined on a random variable with a given probability distribution. Moreover, arithmetic mean is generally unweighted.</p>
<p><strong>Median (<span class="math inline">\(\nu)\)</span>.</strong> Middle value separating the greater and lesser halves of a data set. Example: Given data set <span class="math inline">\(\{1,2,2,3,4,7,9\}\)</span>, the median is <span class="math inline">\(\nu = 3\)</span>.</p>
<p><strong>Mode (<span class="math inline">\(\theta\)</span>).</strong> Most frequent value in a data set. Example: Given data set <span class="math inline">\(\{1,2,2,3,4,7,9\}\)</span>, the mode is <span class="math inline">\(\theta = 2\)</span>.</p>
<p><strong>Mid-range.</strong> The arithmetic mean of the maximum and minimum values in a data set. Example: Given data set <span class="math inline">\(\{1,2,2,3,4,7,9\}\)</span>, the midrange is <span class="math inline">\(\frac{9+1}{2} = 5\)</span>.</p>
<p>Values far from the mode are called <em>outliers</em>, such as very infrequent, occasional or false experimental data records. The mode and the median are relatively robust in the presence of outliers, while the arithmetic mean is rather sensitive. The mid-range is extremely sensitive to the values of outliers, thus it is rarely used in practical statistical analysis as it fails to provide a robust estimator for most distributions of interest.</p>
<p>For an arbitrary distribution, the arithmetic mean <span class="math inline">\(\mu\)</span>, the median <span class="math inline">\(\nu\)</span> and the mode <span class="math inline">\(\theta\)</span> may appear in any order.</p>
<p>Besides the arithmetic mean, other means of measuring a data set are also defined:</p>
<p><strong>Geometric mean (GM).</strong> Defined as <span class="math inline">\(\left(\prod_{i=1}^n x_i \right)^\frac{1}{n}\)</span>.</p>
<p><strong>Harmonic mean (HM).</strong> Defined as <span class="math inline">\(\frac{n}{\sum_{i=1}^n \frac{1}{x_i}}\)</span>. (Related to the harmonic series <span class="math inline">\(\sum_{n=1}^\infty \frac{1}{n}\)</span>.)</p>
<p>Arithmetic mean (AM), geometric mean (GM) and harmonic mean (HM) are sometimes referred to as <em>Pythagorean means</em>, which are special cases of the <em>generalized mean</em>:</p>
<p><strong>Generalized mean (power mean; Hölder mean).</strong> Given <span class="math inline">\(x_1,\dots,x_n \in \mathbb{R}^+\)</span>, and <span class="math inline">\(w_1,\dots,w_n \in \mathbb{R}\)</span> with <span class="math inline">\(\sum_{i=1}^n w_i = 1\)</span>. For <span class="math inline">\(p \in \mathbb{R}, p \neq 0\)</span>, the generalized mean with exponent <span class="math inline">\(p\)</span> of <span class="math inline">\(\{x_1,\dots,x_n\}\)</span> weighted by <span class="math inline">\(\{w_1,\dots,w_n\}\)</span> is defined as <span class="math display">\[\operatorname{M}_p (x_1,\dots,x_n) = \left( \sum_{i=1}^n w_i x_i^p \right)^\frac{1}{p}\]</span> For <span class="math inline">\(p = 0\)</span>, we assume that it is equal to the geometric mean (which is the limit of means with exponents approaching zero): <span class="math display">\[\operatorname{M}_0 (x_1,\dots,x_n) = \lim_{p \to 0} \operatorname{M}_{p}(x_1,\dots,x_n) = \prod_{i=1}^n x_i^{w_i}\]</span> The unweighted means correspond to setting all <span class="math inline">\(w_i = \frac{1}{n}\)</span>.</p>
<p>We can redefine Pythagorean means using the generalized mean with different parameters <span class="math inline">\(p\)</span>:</p>
<ul>
<li>(Harmonic mean, <span class="math inline">\(p=-1\)</span>) <span class="math inline">\(\operatorname{HM}(x_1,\dots,x_n) = \operatorname{M}_{-1}(x_1,\dots,x_n) = \frac{n}{\sum_{i=1}^n \frac{1}{x_i}}\)</span>.</li>
<li>(Geometric mean, <span class="math inline">\(p=0\)</span>) <span class="math inline">\(\operatorname{GM}(x_1,\dots,x_n) = \operatorname{M}_{0}(x_1,\dots,x_n) = \left(\prod_{i=1}^n x_i \right)^\frac{1}{n}\)</span>.</li>
<li>(Arithmetic mean, <span class="math inline">\(p=1\)</span>) <span class="math inline">\(\operatorname{AM}(x_1,\dots,x_n) = \operatorname{M}_{1}(x_1,\dots,x_n) = \frac{1}{n} \sum_{i=1}^n x_i\)</span>.</li>
</ul>
<p><strong>Theorem 1.1.2. (Generalized mean inequality)</strong> If <span class="math inline">\(p, q \in \mathbb{R}\)</span> and <span class="math inline">\(p &lt; q\)</span>, then <span class="math display">\[\operatorname{M}_p(x_1,\dots,x_n) \leq \operatorname{M}_q(x_1,\dots,x_n)\]</span> The equality holds if and only if <span class="math inline">\(x_1 = \dots = x_n\)</span> (<span class="math inline">\(= \operatorname{M}_p(x_1,\dots,x_n)\)</span>).</p>
</section>
<section id="dispersion-variability" class="level2">
<h2><span class="header-section-number">1.2</span> Dispersion / Variability</h2>
<p><strong>Minimum (first or smallest order statistic).</strong> The smallest value in the data set. Defined using the generalized mean: <span class="math display">\[\operatorname{min}\{x_1,\dots,x_n\} = \operatorname{M}_{-\infty}(x_1,\dots,x_n)\]</span></p>
<p><strong>Maximum (largest order statistic).</strong> The largest value in the data set. Defined using the generalized mean: <span class="math display">\[\operatorname{max}\{x_1,\dots,x_n\} = \operatorname{M}_{+\infty}(x_1,\dots,x_n)\]</span></p>
<p><strong>Range.</strong> The size of the smallest interval which contains all the data; it is equal to the difference between the maximum and minimum: <span class="math display">\[\operatorname{Range}\{x_1,\dots,x_n\} = \operatorname{max}\{x_1,\dots,x_n\} - \operatorname{min}\{x_1,\dots,x_n\}\]</span> Intuitively, the range provides a naïve indication of statistical dispersion of the data set.</p>
<p><strong>Remark 1.2.1. (Difference between range and support)</strong> Recall that the support of a given probability distribution is the closure of the set of all possible values of a random variable having that distribution. The range is defined for a sample (data set), and does not necessarily include every possible value of the population.</p>
<p><strong>Interquartile range (IQR; mid-spread; H-spread).</strong> The difference between the 75th and the 25th percentiles (i.e., the 3rd and the 1st quartiles).</p>
<p>Unlike the regular (full) range, the IQR is a 25%-trimmed estimator thus it is more robust in the presence of outliers.</p>
<p><strong>Maximum absolute deviation.</strong> Defined as <span class="math display">\[\max_i |x_i - m|\]</span> where <span class="math inline">\(m\)</span> can take the value of any chosen measure of central tendency of the data set (e.g., the mean <span class="math inline">\(\mu\)</span> or the median <span class="math inline">\(\nu\)</span>).</p>
<p><strong>Mean absolute deviation (MAD; average absolute deviation).</strong> Defined as <span class="math display">\[\frac{1}{n} \sum_{i=1}^n |x_i - m|\]</span> where <span class="math inline">\(m\)</span> can take the value of any chosen measure of central tendency of the data set (e.g., the mean <span class="math inline">\(\mu\)</span> or the median <span class="math inline">\(\nu\)</span>).</p>
<p>Clearly, the MAD is a more robust measure of dispersion than the maximum absolute deviation, which is highly sensitive to the values of outliers.</p>
<p><strong>Sample variance.</strong> The (unbiased) sample variance <span class="math inline">\(s^2\)</span> is an unbiased estimator of the population variance <span class="math inline">\(\sigma^2\)</span>: <span class="math display">\[s^2 = \frac{n}{n-1}s_n^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2\]</span> <span class="math inline">\(s\)</span> is also called the <strong>sample standard deviation</strong>.</p>
<p><strong>Remark 1.2.2. (Bessel’s correction)</strong> The use of the term <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span> is called Bessel’s correction. It corrects the bias in the estimation of the population variance; however, it often increases the mean squared error (MSE) in these estimations. <span class="math inline">\(\bar{x}\)</span> in this formula should be interpreted as the sample (arithmetic) mean. When the population mean is already known, there is no need to use Bessel’s correction, since the use of the population mean will not lead to any bias for estimating the population variance.</p>
<p><strong>Coefficient of variation (CV; relative standard deviation).</strong> The coefficient of variation is defined as the ratio of the sample standard deviation <span class="math inline">\(s\)</span> to the sample mean <span class="math inline">\(\bar{x}\)</span>: <span class="math display">\[\widehat{c_{\rm v}} = \frac{s}{\bar{x}}\]</span> Note that this is a biased estimator. The correction varies for different distributions of data.</p>
<p><strong>Index of dispersion (coefficient of dispersion; relative variance; variance-to-mean ratio; VMR).</strong> Defined as <span class="math display">\[\widehat{D} = \frac{s^2}{\bar{x}}\]</span></p>
<p>CV and VMR are normalized values of the sample standard deviation and the sample variance respectively, thus they are also called the relative standard deviation and the relative variance, and are only defined when the sample mean <span class="math inline">\(\bar{x}\)</span> is non-zero.</p>
</section>
<section id="shape" class="level2">
<h2><span class="header-section-number">1.3</span> Shape</h2>
<p><strong>Sample skewness.</strong> Defined as <span class="math display">\[g_1 = \frac{m_3}{m_2^{3/2}} = \frac{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^3}{(\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2)^{3/2}}\]</span> where <span class="math inline">\(m_i\)</span> is the <span class="math inline">\(i\)</span>th sample central moment. Note that this is a biased estimator.</p>
<p>In practice, sample skewness is a measure of the asymmetry of the distribution of a data set about its mean. The skewness of any univariate normal distribution is 0 (symmetric).</p>
<p><strong>Sample excess kurtosis.</strong> Defined as <span class="math display">\[g_2 = \frac{m_4}{m_2^2} - 3 = \frac{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^4}{(\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2)^2} - 3\]</span> where <span class="math inline">\(m_i\)</span> is the <span class="math inline">\(i\)</span>th sample central moment. Note that this is a biased estimator.</p>
<p>In practice, larger sample kurtosis indicates that the data set has more extreme outliers, so there could be a problem with sampling. The kurtosis of any univariate normal distribution is 3 (thus the sample excess kurtosis should be ideally close to 0).</p>
</section>
<section id="correlation" class="level2">
<h2><span class="header-section-number">1.4</span> Correlation</h2>
</section>
</section>
<section id="inferential-statistics" class="level1">
<h1><span class="header-section-number">2</span> Inferential Statistics</h1>
<hr />
<p>Related topics:</p>
<ul>
<li><a href="/math/probability/">Probability</a></li>
<li><a href="/info/">Information theory</a></li>
</ul>
</section>
      </div>
      <footer>
        <!-- TO BE MODIFIED BY NEED -->
        <a title="Keyboard shortcut: q"
           href="..">
          <i class="fa fa-angle-double-left" aria-hidden="true"></i>
          <code>Parent</code>
        </a> |
        <a class="raw" accesskey="r"
           title="Keyboard shortcut: R"
           href="https://wiki.soimort.org/math/statistics/src.md">
          <i class="fa fa-code" aria-hidden="true"></i>
          <code>Raw</code>
        </a> |
        <a class="history" accesskey="h"
           title="Keyboard shortcut: H"
           href="https://github.com/soimort/wiki/commits/gh-pages/math/statistics/src.md">
          <i class="fa fa-history" aria-hidden="true"></i>
          <code>History</code>
        </a> |
        <a class="edit" accesskey="e"
           title="Keyboard shortcut: E"
           href="https://github.com/soimort/wiki/edit/gh-pages/math/statistics/src.md">
          <i class="fa fa-code-fork" aria-hidden="true"></i>
          <code>Edit</code>
        </a> |
        <a title="Keyboard shortcut: p"
           href="javascript:window.print();">
          <i class="fa fa-print" aria-hidden="true"></i>
          <code>Print</code>
        </a> |
        <a title="Keyboard shortcut: ."
           href="https://wiki.soimort.org/math/statistics">
          <i class="fa fa-anchor" aria-hidden="true"></i>
          <code>Permalink</code>
        </a> |
        Last updated: <span id="update-time">2017-01-08</span>
      </footer>
    </article></main>
  </body>
</html>
